{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e19fa0ca",
   "metadata": {},
   "source": [
    "# Target-disease genetic evidence from Open Targets Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7723f216",
   "metadata": {},
   "source": [
    "This code is meant to prepare ranked lists of genes for all diseases from Open Targets platform with amount of genetically supported genes (genetically and somatic mutations for oncological traits) >= 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6b66823",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkSession, DataFrame, Window\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     col, countDistinct, row_number, \u001b[38;5;28msum\u001b[39m \u001b[38;5;28;01mas\u001b[39;00m spark_sum,\n\u001b[1;32m      4\u001b[0m     broadcast, array_contains\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgcsfs\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame, Window\n",
    "from pyspark.sql.functions import (\n",
    "    col, countDistinct, row_number, sum as spark_sum,\n",
    "    broadcast, array_contains\n",
    ")\n",
    "import gcsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6613fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # \"ot_genetics_portal\": 1,\n",
    "    \"gwas_credible_sets\": 1,\n",
    "    \"gene_burden\": 1,\n",
    "    \"eva\": 1,\n",
    "    \"genomics_england\": 1,\n",
    "    \"gene2phenotype\": 1,\n",
    "    \"uniprot_literature\": 1,\n",
    "    \"uniprot_variants\": 1,\n",
    "    \"orphanet\": 1,\n",
    "    \"clingen\": 1,\n",
    "    \"cancer_gene_census\": 1,\n",
    "    \"intogen\": 1,\n",
    "    \"eva_somatic\": 1,\n",
    "    \"cancer_biomarkers\": 1,\n",
    "    \"chembl\": 1,\n",
    "    \"crispr_screen\": 1,\n",
    "    \"crispr\": 1,\n",
    "    \"slapenrich\": 0.5,\n",
    "    \"progeny\": 0.5,\n",
    "    \"reactome\": 1,\n",
    "    \"sysbio\": 0.5,\n",
    "    \"europepmc\": 0.2,\n",
    "    \"expression_atlas\": 0.2,\n",
    "    \"impc\": 0.2,\n",
    "    \"ot_crispr_validation\": 0.5,\n",
    "    \"ot_crispr\": 0.5,\n",
    "    \"encore\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed0c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oncology MONDO code constant\n",
    "ONCOLOGY_ID = \"MONDO_0045024\"\n",
    "\n",
    "# Initialize Spark\n",
    "spark = SparkSession.builder.appName(\"ProcessDiseasesNotebook\").getOrCreate()\n",
    "\n",
    "# 1. Load inputs by specifying your GCS paths directly\n",
    "evidence_path = \"gs://your-bucket/association_by_datasource_indirect\"\n",
    "target_path   = \"gs://your-bucket/targets\"\n",
    "disease_path  = \"gs://your-bucket/disease_to_area\"\n",
    "output_dir    = \"gs://your-bucket/processed\"\n",
    "include_animal_models = True   # or False\n",
    "\n",
    "# 2. Read and prepare DataFrames\n",
    "\n",
    "evidence = spark.read.parquet(evidence_path)\n",
    "target_df = (\n",
    "    spark.read.parquet(target_path)\n",
    "         .select(col(\"id\").alias(\"targetId\"), col(\"approvedSymbol\"))\n",
    ")\n",
    "evidence = evidence.join(broadcast(target_df), on=\"targetId\", how=\"left\")\n",
    "\n",
    "disease_df = (\n",
    "    spark.read.parquet(disease_path)\n",
    "         .select(col(\"id\").alias(\"diseaseId\"), col(\"therapeuticArea\"))\n",
    ")\n",
    "\n",
    "# 3. Define your data source weights\n",
    "weights = {\n",
    "    # \"datasourceA\": 1.0,\n",
    "    # \"datasourceB\": 0.5,\n",
    "    # ...\n",
    "}\n",
    "\n",
    "# 4. Build evidence type lists based on animal-model flag\n",
    "oncology_types     = [\"genetic_association\", \"somatic_mutation\"]\n",
    "non_oncology_types = [\"genetic_association\"]\n",
    "if include_animal_models:\n",
    "    oncology_types.append(\"animal_model\")\n",
    "    non_oncology_types.append(\"animal_model\")\n",
    "\n",
    "# 5. Define processing functions\n",
    "\n",
    "def _compute_scores(ev: DataFrame, evidence_types: list) -> DataFrame:\n",
    "    # Build regex from types\n",
    "    pattern = \"|\".join(evidence_types)\n",
    "    # Filter by types and by â‰¥500 genes\n",
    "    valid = (\n",
    "        ev.filter(col(\"datatypeId\").rlike(pattern))\n",
    "          .groupBy(\"diseaseId\")\n",
    "          .agg(countDistinct(\"approvedSymbol\").alias(\"nGenes\"))\n",
    "          .filter(col(\"nGenes\") >= 500)\n",
    "    )\n",
    "    weights_df = spark.createDataFrame(\n",
    "        list(weights.items()), schema=[\"datasourceId\", \"weight\"]\n",
    "    )\n",
    "    df = (\n",
    "        ev.join(valid.select(\"diseaseId\"), on=\"diseaseId\")\n",
    "          .join(broadcast(weights_df), on=\"datasourceId\", how=\"left\")\n",
    "          .withColumn(\"score_weighted\", col(\"score\") * col(\"weight\"))\n",
    "    )\n",
    "    # First-level window\n",
    "    win1 = Window.partitionBy(\"diseaseId\",\"datatypeId\",\"approvedSymbol\",\"targetId\").orderBy(col(\"score_weighted\").desc())\n",
    "    df1 = (\n",
    "        df.withColumn(\"rank1\", row_number().over(win1))\n",
    "          .withColumn(\"term1\", col(\"score_weighted\") / (col(\"rank1\")**2))\n",
    "          .groupBy(\"diseaseId\",\"datatypeId\",\"approvedSymbol\",\"targetId\")\n",
    "          .agg(spark_sum(\"term1\").alias(\"sourceSum\"))\n",
    "    )\n",
    "    # Second-level window\n",
    "    win2 = Window.partitionBy(\"diseaseId\",\"approvedSymbol\",\"targetId\").orderBy(col(\"sourceSum\").desc())\n",
    "    df2 = (\n",
    "        df1.withColumn(\"rank2\", row_number().over(win2))\n",
    "           .withColumn(\"overallScore\", col(\"sourceSum\") / (col(\"rank2\")**2))\n",
    "           .filter(col(\"overallScore\").isNotNull())\n",
    "    )\n",
    "    return df2\n",
    "\n",
    "# 6. Process oncology\n",
    "\n",
    "ev_onc = (\n",
    "    evidence.join(broadcast(disease_df), on=\"diseaseId\")\n",
    "            .filter(array_contains(col(\"therapeuticArea\"), ONCOLOGY_ID))\n",
    ")\n",
    "result_onc = _compute_scores(ev_onc, oncology_types)\n",
    "# Write out\n",
    "result_onc.select(\"diseaseId\",\"approvedSymbol\",\"targetId\",\"overallScore\") \\\n",
    "           .repartition(\"diseaseId\") \\\n",
    "           .write.mode(\"overwrite\") \\\n",
    "           .partitionBy(\"diseaseId\") \\\n",
    "           .parquet(f\"{output_dir}/oncology\")\n",
    "\n",
    "# 7. Process non-oncology\n",
    "\n",
    "ev_non = (\n",
    "    evidence.join(broadcast(disease_df), on=\"diseaseId\")\n",
    "            .filter(~array_contains(col(\"therapeuticArea\"), ONCOLOGY_ID))\n",
    ")\n",
    "result_non = _compute_scores(ev_non, non_oncology_types)\n",
    "# Write out\n",
    "result_non.select(\"diseaseId\",\"approvedSymbol\",\"targetId\",\"overallScore\") \\\n",
    "           .repartition(\"diseaseId\") \\\n",
    "           .write.mode(\"overwrite\") \\\n",
    "           .partitionBy(\"diseaseId\") \\\n",
    "           .parquet(f\"{output_dir}/non_oncology\")\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e00e498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a360b49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
