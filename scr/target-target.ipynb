{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "856135c1",
   "metadata": {},
   "source": [
    "This code is pasted from IBD_pathway_to_cell from similarity_mvp and should be rewritten to spark to process data more effeciently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7644035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, split, array_distinct\n",
    "from pyspark.ml.feature import MinHashLSH\n",
    "from pyspark.ml.linalg import Vectors\n",
    "import pyspark.sql.functions as F\n",
    "import os\n",
    "import numpy as np\n",
    "import gcsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2799bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/28 16:18:10 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/04/28 16:18:10 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/04/28 16:18:10 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/04/28 16:18:10 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a94715",
   "metadata": {},
   "source": [
    "# Similarity matrix for propagation results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f12f9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "For MVP: \n",
    "\n",
    "presence or absence of target in pathways (0/1)\n",
    "\n",
    "Jaccard for distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a275554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_jaccard_similarity_spark_minhash(input_gcs_dir, output_gcs_dir, folders_to_process, num_hash_tables=5):\n",
    "    \"\"\"\n",
    "    Process CSV files in specified folders within a GCS directory and calculate Jaccard similarity matrices using Spark MinHashLSH (approximate).\n",
    "\n",
    "    Args:\n",
    "        input_gcs_dir (str): Input GCS directory path.\n",
    "        output_gcs_dir (str): Output GCS directory path.\n",
    "        folders_to_process (list): List of folder names within the input directory to process.\n",
    "        num_hash_tables (int): Number of hash tables for MinHash (higher = more accuracy, slower).\n",
    "\n",
    "    Output:\n",
    "        Saves approximate similarity results into output GCS directory.\n",
    "    \"\"\"\n",
    "\n",
    "    input_gcs_dir = input_gcs_dir.rstrip(\"/\")\n",
    "    output_gcs_dir = output_gcs_dir.rstrip(\"/\")\n",
    "\n",
    "    for folder_name in folders_to_process:\n",
    "        folder_path = f\"{input_gcs_dir}/{folder_name}\"\n",
    "        output_folder_path = f\"{output_gcs_dir}/{folder_name}\"\n",
    "\n",
    "        # Read all CSVs inside the folder\n",
    "        df = spark.read.option(\"header\", True).csv(f\"{folder_path}/*.csv\")\n",
    "\n",
    "        # Check if required columns exist\n",
    "        expected_cols = {'propagated_edge', 'Term'}\n",
    "        if not expected_cols.issubset(set(df.columns)):\n",
    "            print(f\"Skipping folder {folder_name}: missing required columns.\")\n",
    "            continue\n",
    "\n",
    "        # Explode propagated_edge column\n",
    "        df_exploded = df.withColumn(\n",
    "            \"propagated_edge_exploded\", \n",
    "            explode(split(col(\"propagated_edge\"), \",\"))\n",
    "        ).dropna(subset=[\"propagated_edge_exploded\"])\n",
    "\n",
    "        # Group by target and collect associated terms\n",
    "        target_terms = df_exploded.groupBy(\"propagated_edge_exploded\") \\\n",
    "            .agg(F.collect_set(\"Term\").alias(\"terms\"))\n",
    "\n",
    "        # Index the terms (since MinHash needs fixed-size numeric vectors)\n",
    "        # Create a dictionary: term -> index\n",
    "        all_terms = df_exploded.select(\"Term\").distinct().rdd.map(lambda r: r[0]).collect()\n",
    "        term_to_index = {term: idx for idx, term in enumerate(all_terms)}\n",
    "\n",
    "        # Transform terms into SparseVectors\n",
    "        def terms_to_vector(terms):\n",
    "            indices = [term_to_index[term] for term in terms if term in term_to_index]\n",
    "            values = [1.0] * len(indices)\n",
    "            size = len(term_to_index)\n",
    "            return Vectors.sparse(size, list(zip(indices, values)))\n",
    "\n",
    "        terms_to_vector_udf = F.udf(terms_to_vector)\n",
    "\n",
    "        target_terms = target_terms.withColumn(\"features\", terms_to_vector_udf(col(\"terms\")))\n",
    "\n",
    "        # Initialize MinHashLSH model\n",
    "        mh = MinHashLSH(inputCol=\"features\", outputCol=\"hashes\", numHashTables=num_hash_tables)\n",
    "        model = mh.fit(target_terms)\n",
    "\n",
    "        # Compute pairwise similarities\n",
    "        similarities = model.approxSimilarityJoin(target_terms, target_terms, threshold=1.0, distCol=\"JaccardDistance\")\n",
    "\n",
    "        # Select relevant columns and format\n",
    "        similarity_df = similarities.select(\n",
    "            col(\"datasetA.propagated_edge_exploded\").alias(\"target1\"),\n",
    "            col(\"datasetB.propagated_edge_exploded\").alias(\"target2\"),\n",
    "            (1 - col(\"JaccardDistance\")).alias(\"similarity\")\n",
    "        ).filter(\"target1 <= target2\")  # Avoid duplicates (symmetry)\n",
    "\n",
    "        # Save the similarity results\n",
    "        similarity_df.write.mode('overwrite').option(\"header\", True).csv(f\"{output_folder_path}\")\n",
    "\n",
    "        print(f\"Processed (MinHash) and uploaded: {output_folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135d9160",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calculate_jaccard_similarity_spark_minhash' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://ot-team/polina/pathway_propagation_validation_v2/similarity_mtx/jaccard_spark\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m library \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKEGG_2021_Human\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m \u001b[43mcalculate_jaccard_similarity_spark_minhash\u001b[49m(gsea_dir, output_dir, library)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calculate_jaccard_similarity_spark_minhash' is not defined"
     ]
    }
   ],
   "source": [
    "gsea_dir = \"gs://ot-team/polina/pathway_propagation_validation_v2/gsea_output\"\n",
    "output_dir = \"gs://ot-team/polina/pathway_propagation_validation_v2/similarity_mtx/jaccard_spark\"\n",
    "\n",
    "library = [\"KEGG_2021_Human\"]\n",
    "\n",
    "calculate_jaccard_similarity_spark_minhash(gsea_dir, output_dir, library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abed3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
