{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4868985",
   "metadata": {},
   "source": [
    "! This code is pasted from IBD_pathway_to_cell from similarity_mvp and haven't been run !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805139b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import collect_list, concat_ws, col, when, udf, row_number, sum as spark_sum, max as spark_max, create_map, lit, min as spark_min\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql import Window\n",
    "from itertools import chain\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import Row\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "import gcsfs\n",
    "from pathlib import Path\n",
    "import blitzgsea as blitz\n",
    "from functools import reduce\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve\n",
    "from sklearn.utils import resample\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e26fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_gsea_propagation_missing_dir_gcs(input_gcs_dir, output_gcs_dir, libraries, file_suffixes, pval_cutoff=0.05):\n",
    "    \"\"\"\n",
    "    Perform GSEA propagation and save results in GCS directories, creating library-specific subfolders.\n",
    "\n",
    "    Args:\n",
    "        input_gcs_dir (str): GCS path to the input directory (e.g., \"gs://bucket-name/input-dir/\").\n",
    "        output_gcs_dir (str): GCS path to the output directory (e.g., \"gs://bucket-name/output-dir/\").\n",
    "        libraries (list): List of library names to use for GSEA.\n",
    "        file_suffixes (list): List of suffixes to filter files (e.g., \"_gsea_in\").\n",
    "        pval_cutoff (float): P-value cutoff for filtering significant results.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Initialize GCS filesystem\n",
    "    fs = gcsfs.GCSFileSystem()\n",
    "\n",
    "    # Ensure both input and output directories are valid GCS paths\n",
    "    if not input_gcs_dir.startswith(\"gs://\") or not output_gcs_dir.startswith(\"gs://\"):\n",
    "        raise ValueError(\"Both input and output directories must be GCS paths starting with 'gs://'.\")\n",
    "\n",
    "    # List all files in the input directory\n",
    "    input_files = [file for file in fs.ls(input_gcs_dir) if any(suffix in file for suffix in file_suffixes)]\n",
    "\n",
    "    summary_data = []\n",
    "\n",
    "    for input_file_path in input_files:\n",
    "        # Read the file\n",
    "        print(f\"Processing file: {input_file_path}\")\n",
    "        with fs.open(input_file_path, 'r') as f:\n",
    "            df = pd.read_csv(f)\n",
    "\n",
    "        # Count rows before removing NaN values\n",
    "        initial_row_count = df.shape[0]\n",
    "\n",
    "        # Convert 'overallScore' to numeric, invalid parsing will be set as NaN\n",
    "        df['overallScore'] = pd.to_numeric(df['overallScore'], errors='coerce')\n",
    "\n",
    "        # Drop rows where 'overallScore' is NaN\n",
    "        df_cleaned = df.dropna(subset=['overallScore'])\n",
    "\n",
    "        # Count rows after removing NaN values\n",
    "        final_row_count = df_cleaned.shape[0]\n",
    "        print(f\"File: {os.path.basename(input_file_path)}, Initial Rows: {initial_row_count}, Rows after filtering: {final_row_count}\")\n",
    "\n",
    "        # Skip if no valid rows remain\n",
    "        if final_row_count == 0:\n",
    "            print(f\"No valid data after filtering for file: {input_file_path}\")\n",
    "            continue\n",
    "\n",
    "        # Rename columns: 'overallScore' as '1' for numeric ranking, 'approvedSymbol' as '0'\n",
    "        df_cleaned = df_cleaned.rename(columns={'overallScore': '1', 'approvedSymbol': '0'})\n",
    "\n",
    "        # Extract gene symbols\n",
    "        gene_symbols = set(df_cleaned['0'].unique())\n",
    "\n",
    "        # Perform GSEA for each library\n",
    "        for lib in libraries:\n",
    "            # Create a unique subfolder for this library in the output directory\n",
    "            lib_folder = f\"{output_gcs_dir}/{lib}\"\n",
    "            fs.mkdirs(lib_folder, exist_ok=True)\n",
    "            print(f\"Library folder created: {lib_folder}\")\n",
    "\n",
    "            # Get the library from enrichr\n",
    "            library = blitz.enrichr.get_library(lib)\n",
    "\n",
    "            # Aggregate all unique genes in the current library\n",
    "            library_genes = set()\n",
    "            for genes in library.values():\n",
    "                library_genes.update(genes)\n",
    "\n",
    "            # Determine missing genes for this library\n",
    "            missing_genes = gene_symbols - library_genes\n",
    "            num_missing_genes = len(missing_genes)\n",
    "\n",
    "            # Perform GSEA\n",
    "            result = blitz.gsea(df_cleaned[['0', '1']].sort_values(by='1', ascending=False), library, processes=4)\n",
    "            # print(f\"Performed GSEA for {os.path.basename(input_file_path)} with library {lib}. Results shape: {result.shape}\")\n",
    "\n",
    "            # Apply the p-value cutoff\n",
    "            result_sign = result[result['pval'] <= pval_cutoff].copy()\n",
    "            print(f\"Significant results after pval filtering: {result_sign.shape[0]}\")\n",
    "\n",
    "            # Skip if no significant results remain\n",
    "            if result_sign.empty:\n",
    "                print(f\"No significant results for file: {input_file_path} with library {lib}\")\n",
    "                continue\n",
    "\n",
    "            # Ensure 'Term' is the index before propagation\n",
    "            result_sign_propagated = result_sign.copy()\n",
    "            result_sign_propagated['propagated_edge'] = result_sign_propagated.index.map(\n",
    "                lambda term: ','.join(library.get(term, []))\n",
    "            )\n",
    "\n",
    "            # Save the results to the library-specific subfolder\n",
    "            output_file_name = f\"{os.path.splitext(os.path.basename(input_file_path))[0]}_gsea_{lib}_pval{pval_cutoff}.csv\"\n",
    "            output_file_path = f\"{lib_folder}/{output_file_name}\"\n",
    "            with fs.open(output_file_path, 'w') as f_out:\n",
    "                result_sign_propagated.to_csv(f_out, index=True)\n",
    "            print(f\"Results saved to {output_file_path}\")\n",
    "\n",
    "            # Summarize the results\n",
    "            summary_data.append({\n",
    "                'file': os.path.basename(input_file_path),\n",
    "                'library': lib,\n",
    "                'valid_targets': final_row_count,\n",
    "                'initial_targets': initial_row_count,\n",
    "                'missing_genes_count': num_missing_genes,\n",
    "            })\n",
    "\n",
    "    # Save summary data\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_output_path = f\"{output_gcs_dir}/gsea_summary.csv\"\n",
    "    with fs.open(summary_output_path, 'w') as summary_file:\n",
    "        summary_df.to_csv(summary_file, index=False)\n",
    "    print(f\"Summary results saved to {summary_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f036ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_gcs_dir = \"gs://ot-team/polina/pathway_propagation_validation_v2/target_disease_as\"\n",
    "output_gcs_dir = \"gs://ot-team/polina/pathway_propagation_validation_v2/gsea_output\"\n",
    "\n",
    "libraries = [\"KEGG_2021_Human\",\n",
    "            \"Reactome_Pathways_2024\",\n",
    "            \"WikiPathways_2024_Human\", \n",
    "            \"GO_Biological_Process_2023\"]\n",
    "pval_cutoff = 0.05\n",
    "file_suffixes = [\"_ge_mm\", \"_ge_mm_som\"]\n",
    "\n",
    "perform_gsea_propagation_missing_dir_gcs(input_gcs_dir, output_gcs_dir, libraries, file_suffixes, pval_cutoff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
